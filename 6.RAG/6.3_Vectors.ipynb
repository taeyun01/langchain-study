{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding의 의미는 사람이 읽는 텍스트를 컴퓨터가 이해할 수 있는 숫자들로 변환하는 작업\n",
    "# 벡터, 정확히는 vectorization(벡터화)이라는 작업\n",
    "# 우리가 만든 문서마다 각각의 벡터를 만들어줌\n",
    "\n",
    "# 3D벡터| 남성성 | 여성성 | 왕족스러움(royal) 이 있다고 가정\n",
    "# king |  0.9 |  0.1  |  1.0\n",
    "# queen|  0.1 |   1   |  1.0\n",
    "# man  |  0.9 |  0.1  |  0.0\n",
    "# woman|  0.1 |   1   |  0.0\n",
    "\n",
    "# 이렇게 점수를 매겨 각 단어가 해당 특성을 얼마나 반영했는지 평가.\n",
    "# 벡터는 천개 이상의 차원을 가지고 있음,\n",
    "# 분류가 굉장히 많은데 예를 들어 얼만큼의 친절함이 있는지, 부유한지, 가난한지 등등등 나눠서 세밀하게 표현할 수 있고\n",
    "# 다른 단어를 얻기 위해 가진 단어를 가지고 연산을 함\n",
    "# 예를 들어 king - man 을 한다고 가정하면\n",
    "# king |  0.9 |  0.1  |  1.0\n",
    "# man  |  0.9 |  0.1  |  0.0\n",
    "#         0.0 |  0.0  |  1.0 = 그럼 이단어는 왕족스러움이라는 특성을 가지고 있어 royal이 나오게 된다\n",
    "# 우리 문서들을 전부 숫자로 변환, 그럼 우린 벡터에 대한 search(검색)작업을 할 수 있게 됨\n",
    "\n",
    "# 즉, 비슷한 벡터를 찾을 수 있게 됨. 이게 바로 추천 알고리즘들이 작동하는 방식\n",
    "# Embedding은 벡터들을 만드는 작업이다.\n",
    "# 우린 날것의 벡터를 GPT에 전달하지 않는다.\n",
    "# 벡터를 사용해서 비슷한 문서들을 검색한다. 같은 벡터 공간에 존재하는 문서들을 검색\n",
    "# RAG를 할 때 벡터를 사용해서 비슷한 문서들을 검색하는 방식으로 작동한다.\n",
    "# 이게 우리가 embedding을 해주는 이유이다.\n",
    "# 그 벡터들을 가지고 벡터 데이터베이스 검색을 행하게 된다.\n",
    "# 연관성이 높은 문서들을 찾아내서 그 문서들을 LLM에게 전달한다.\n",
    "# 그렇게 우리의 데이터에 대한 질문에 답할 수 있게 되는 것이다.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
