import streamlit as st
from langchain.chat_models import ChatOpenAI
from langchain.document_loaders import UnstructuredFileLoader
from langchain.text_splitter import CharacterTextSplitter
from langchain.embeddings import OpenAIEmbeddings, CacheBackedEmbeddings
from langchain.vectorstores import FAISS
from langchain.storage import LocalFileStore
from langchain.prompts import ChatPromptTemplate
from langchain.schema.runnable import RunnablePassthrough

st.set_page_config(page_title="DocumentGPT", page_icon="ğŸ“")

st.title("DocumentGPT")

st.markdown("""
íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ëŒ€í™”ë¥¼ ë‚˜ëˆ„ì–´ë³´ì„¸ìš”!
""")

# ì—…ë¡œë“œí•œ íŒŒì¼ì„ ì„ë² ë”©í•˜ëŠ” í•¨ìˆ˜
@st.cache_data(show_spinner="ì—…ë¡œë“œ ì¤‘...")
def embed_file(file):
    file_content = file.read() # ì—…ë¡œë“œëœ íŒŒì¼ì˜ ë‚´ìš©ì„ ì½ì–´ì˜´
    file_path = f"./7.DocumentGPT/.cache/files/{file.name}" # íŒŒì¼ì„ ìºì‹œ ë””ë ‰í† ë¦¬ì— ì €ì¥í•  ê²½ë¡œ ì„¤ì • 
    with open(file_path, "wb") as f: # íŒŒì¼ì„ ìºì‹œ ë””ë ‰í† ë¦¬ì— ë°”ì´ë„ˆë¦¬ ëª¨ë“œë¡œ ì €ì¥
        f.write(file_content)
    cache_dir = LocalFileStore(f"./7.DocumentGPT/.cache/embeddings/{file.name}") # ì„ë² ë”©ì„ ìºì‹œí•  ë””ë ‰í† ë¦¬ ì„¤ì •
    # í…ìŠ¤íŠ¸ ë¶„í• ê¸° ì„¤ì • - ë¬¸ì„œë¥¼ ì²­í¬ ë‹¨ìœ„ë¡œ ë¶„í• 
    splitter = CharacterTextSplitter.from_tiktoken_encoder(
        separator="\n", # ë¬¸ìì—´ì„ ë¶„í• í•˜ëŠ” ê¸°ì¤€
        chunk_size=600,  # ê° ì²­í¬ì˜ ìµœëŒ€ í¬ê¸°
        chunk_overlap=100,  # ì²­í¬ ê°„ ì¤‘ë³µë˜ëŠ” ë¬¸ì ìˆ˜
    )
    loader = UnstructuredFileLoader(file_path) # íŒŒì¼ ë¡œë”ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¬¸ì„œ ë¡œë“œ
    docs = loader.load_and_split(text_splitter=splitter) # ë¬¸ì„œë¥¼ ì²­í¬ ë‹¨ìœ„ë¡œ ë¶„í• 
    embeddings = OpenAIEmbeddings() # OpenAI ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
    cached_embeddings = CacheBackedEmbeddings.from_bytes_store(embeddings, cache_dir) # ì„ë² ë”©ì„ ìºì‹œí•˜ì—¬ ì¬ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ì„¤ì •
    vectorstore = FAISS.from_documents(docs, cached_embeddings) # ë¶„í• ëœ ë¬¸ì„œë¥¼ ë²¡í„° ì €ì¥ì†Œì— ì €ì¥
    retriever = vectorstore.as_retriever() # ë²¡í„° ì €ì¥ì†Œë¥¼ ê²€ìƒ‰ ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜
    return retriever # ê²€ìƒ‰ ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜ëœ ë²¡í„° ì €ì¥ì†Œ ë°˜í™˜

# ì±„íŒ… ë©”ì‹œì§€ë¥¼ í™”ë©´ì— í‘œì‹œí•˜ê³  ì €ì¥í•˜ëŠ” í•¨ìˆ˜
def send_message(message, role, save=True):
    # streamlitì˜ chat_message ì»´í¬ë„ŒíŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ë©”ì‹œì§€ í‘œì‹œ
    with st.chat_message(role):
        st.markdown(message)
    # saveê°€ Trueì¸ ê²½ìš° ë©”ì‹œì§€ë¥¼ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
    if save:
        st.session_state["messages"].append({"message": message, "role": role}) 

# ì´ì „ ëŒ€í™” ë‚´ì—­ì„ í™”ë©´ì— ë‹¤ì‹œ í‘œì‹œí•˜ëŠ” í•¨ìˆ˜
def paint_history():
    # ì„¸ì…˜ì— ì €ì¥ëœ ëª¨ë“  ë©”ì‹œì§€ë¥¼ ìˆœíšŒí•˜ë©° í‘œì‹œ
    for message in st.session_state["messages"]:
        send_message(
            message["message"],
            message["role"],
            save=False,  # ì´ë¯¸ ì €ì¥ëœ ë©”ì‹œì§€ì´ë¯€ë¡œ ë‹¤ì‹œ ì €ì¥í•˜ì§€ ì•ŠìŒ
        )

# ì‚¬ì´ë“œë°”ì— íŒŒì¼ ì—…ë¡œë” ë°°ì¹˜
with st.sidebar:
    file = st.file_uploader(".txt .pdf .docx íŒŒì¼ì„ ì—…ë¡œë“œ í•´ì£¼ì„¸ìš”.", type=["txt", "pdf", "docx"])

# íŒŒì¼ì´ ì—…ë¡œë“œëœ ê²½ìš°
if file:
    retriever = embed_file(file) # íŒŒì¼ì„ ì„ë² ë”©í•˜ì—¬ ê²€ìƒ‰ ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜
    send_message("ëŒ€ë‹µí•  ì¤€ë¹„ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤!", "AI", save=False)
    paint_history() # ì´ì „ ëŒ€í™” ë‚´ì—­ í‘œì‹œ
    message = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.") # ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
    if message:
        send_message(message, "user") # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ ë° ì €ì¥
        send_message("í…ŒìŠ¤íŠ¸~~~~", "ai")
# íŒŒì¼ì´ ì—…ë¡œë“œë˜ì§€ ì•Šì€ ê²½ìš°
else:
    st.session_state["messages"] = [] # ëŒ€í™” ë‚´ì—­ ì´ˆê¸°í™”
